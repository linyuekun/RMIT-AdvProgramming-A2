{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2: Milestone I Natural Language Processing\n",
    "## Task 1. Basic Text Pre-processing\n",
    "#### Student Name: Sukhum Boondecharak\n",
    "#### Student ID: S3940976\n",
    "\n",
    "Date: 04 Oct 2023\n",
    "\n",
    "Version: 1.0\n",
    "\n",
    "Environment: Python 3 and Jupyter notebook\n",
    "\n",
    "Libraries used: please include all the libraries you used in your assignment, e.g.,:\n",
    "* pandas\n",
    "* re\n",
    "* numpy\n",
    "\n",
    "## Introduction\n",
    "\n",
    "The data are separated in 4 sub-folders, which can also be identified as 4 job categories, containing the total of 776 job files. The primary goal for this task is to prepare the raw data for subsequent analysis and model building. This foundational step involves mainly on data cleaning and text preprocessing. We will focus on understanding the data's characteristics, handling missing values, and transforming text data into a suitable format for natural language processing (NLP) tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_files  \n",
    "from nltk import RegexpTokenizer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from itertools import chain\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Examining and loading data\n",
    "- Examine the data folder, including the categories and job advertisment txt documents, etc. Explain your findings here, e.g., number of folders and format of txt files, etc.\n",
    "- Load the data into proper data structures and get it ready for processing.\n",
    "- Extract webIndex and description into proper data structures.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load job data\n",
    "job_data = load_files(r\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Accountant (partqualified) to **** p.a. South East London Our client, a successful manufacturing company has an immediate requirement for an Accountant for permanent role in their modern offices in South East London. The Role: Credit Control Purchase / Sales Ledger Daily collection of debts by phone, letter and email. Handling of ledger accounts Handling disputed accounts and negotiating payment terms Allocating of cash and reconciliation of accounts Adhoc administration duties within the business The Person The ideal candidate will have previous experience in a Credit Control capacity, you will possess exceptional customer service and communication skills together with IT proficiency. You will need to be a part or fully qualified Accountant to be considered for this role'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract descriptions from job data\n",
    "descriptions = []\n",
    "\n",
    "# Define a function to extract the description part from a text\n",
    "def extract_description(text):\n",
    "    start_text = text.find(\"Description: \")\n",
    "    if start_text != -1:\n",
    "        description = text[start_text + len(\"Description: \"):]\n",
    "        return description\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "# Iterate through the loaded data and extract descriptions\n",
    "for text in job_data.data:\n",
    "    description = extract_description(text.decode(\"utf-8\"))  # Decode bytes to string\n",
    "    descriptions.append(description)\n",
    "\n",
    "# See example of the first description    \n",
    "emp = 0\n",
    "descriptions[emp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['72444142',\n",
       " '68687567',\n",
       " '68257980',\n",
       " '71168766',\n",
       " '72441930',\n",
       " '70205492',\n",
       " '69929266',\n",
       " '68814305',\n",
       " '71737507',\n",
       " '69540434',\n",
       " '71199751',\n",
       " '70457475',\n",
       " '72411451',\n",
       " '69001764',\n",
       " '71171544',\n",
       " '68057786',\n",
       " '69040220',\n",
       " '68784018',\n",
       " '69146761',\n",
       " '68256016',\n",
       " '70251801',\n",
       " '68180459',\n",
       " '68056671',\n",
       " '72448172',\n",
       " '69250788',\n",
       " '67639091',\n",
       " '68256188',\n",
       " '69577650',\n",
       " '66600427',\n",
       " '71339723',\n",
       " '72691163',\n",
       " '69989027',\n",
       " '69635720',\n",
       " '69993409',\n",
       " '68356152',\n",
       " '72439398',\n",
       " '69577820',\n",
       " '68708197',\n",
       " '67895483',\n",
       " '71848552',\n",
       " '68257221',\n",
       " '68686791',\n",
       " '68806418',\n",
       " '69188332',\n",
       " '68062805',\n",
       " '68678164',\n",
       " '72680220',\n",
       " '69553242',\n",
       " '71633491',\n",
       " '71171000',\n",
       " '71677705',\n",
       " '62269820',\n",
       " '71677311',\n",
       " '70597736',\n",
       " '68258658',\n",
       " '68553492',\n",
       " '71596865',\n",
       " '69694967',\n",
       " '71750603',\n",
       " '72457901',\n",
       " '70597879',\n",
       " '72673887',\n",
       " '70599432',\n",
       " '71198896',\n",
       " '72672874',\n",
       " '71678606',\n",
       " '69250648',\n",
       " '71848359',\n",
       " '72233918',\n",
       " '70190910',\n",
       " '70256074',\n",
       " '68062611',\n",
       " '66887344',\n",
       " '72240625',\n",
       " '68257449',\n",
       " '70520065',\n",
       " '71849489',\n",
       " '69671186',\n",
       " '69799351',\n",
       " '69000079',\n",
       " '71170782',\n",
       " '68688072',\n",
       " '55414504',\n",
       " '67332022',\n",
       " '71184796',\n",
       " '72397595',\n",
       " '72578233',\n",
       " '72232029',\n",
       " '71745516',\n",
       " '69770990',\n",
       " '67970848',\n",
       " '69056135',\n",
       " '68095319',\n",
       " '72173738',\n",
       " '65451652',\n",
       " '71082952',\n",
       " '72236534',\n",
       " '72241506',\n",
       " '71185283',\n",
       " '68688500',\n",
       " '68194862',\n",
       " '71288404',\n",
       " '72460729',\n",
       " '72446515',\n",
       " '71240896',\n",
       " '72241841',\n",
       " '67639020',\n",
       " '71083870',\n",
       " '69687048',\n",
       " '68347634',\n",
       " '72438284',\n",
       " '68182091',\n",
       " '72446522',\n",
       " '69799803',\n",
       " '68608728',\n",
       " '69147324',\n",
       " '72234499',\n",
       " '68697153',\n",
       " '68784692',\n",
       " '71340157',\n",
       " '68807391',\n",
       " '68057065',\n",
       " '69556224',\n",
       " '68697352',\n",
       " '66753565',\n",
       " '69086048',\n",
       " '68180326',\n",
       " '70028246',\n",
       " '70485873',\n",
       " '55415689',\n",
       " '72448496',\n",
       " '69600219',\n",
       " '69188766',\n",
       " '69000974',\n",
       " '68346273',\n",
       " '69598361',\n",
       " '69004747',\n",
       " '72401303',\n",
       " '62004449',\n",
       " '71800229',\n",
       " '65101527',\n",
       " '68780456',\n",
       " '72227008',\n",
       " '71847011',\n",
       " '69170925',\n",
       " '70028343',\n",
       " '69250765',\n",
       " '68678482',\n",
       " '68576082',\n",
       " '68258357',\n",
       " '71679411',\n",
       " '66399629',\n",
       " '68702817',\n",
       " '66935937',\n",
       " '71812011',\n",
       " '69768475',\n",
       " '69092773',\n",
       " '71674555',\n",
       " '70758175',\n",
       " '69564390',\n",
       " '70255258',\n",
       " '68510409',\n",
       " '68675667',\n",
       " '72238746',\n",
       " '68711980',\n",
       " '68677803',\n",
       " '71852020',\n",
       " '71393735',\n",
       " '69072950',\n",
       " '71555733',\n",
       " '72421706',\n",
       " '72239537',\n",
       " '72236150',\n",
       " '65450489',\n",
       " '72661895',\n",
       " '69805538',\n",
       " '69594171',\n",
       " '72451165',\n",
       " '71671543',\n",
       " '70757932',\n",
       " '50738105',\n",
       " '68677615',\n",
       " '70758173',\n",
       " '68681216',\n",
       " '69024685',\n",
       " '68292692',\n",
       " '68678658',\n",
       " '69073451',\n",
       " '71361732',\n",
       " '69046353',\n",
       " '71748554',\n",
       " '66887701',\n",
       " '70758181',\n",
       " '68682048',\n",
       " '68693284',\n",
       " '70593580',\n",
       " '69931225',\n",
       " '72460315',\n",
       " '72198878',\n",
       " '72479442',\n",
       " '71677246',\n",
       " '71838397',\n",
       " '62017964',\n",
       " '68714905',\n",
       " '71293696',\n",
       " '71393784',\n",
       " '72421504',\n",
       " '69858761',\n",
       " '72457492',\n",
       " '68669224',\n",
       " '68237569',\n",
       " '68691974',\n",
       " '70163439',\n",
       " '71808636',\n",
       " '69170518',\n",
       " '68177629',\n",
       " '70656711',\n",
       " '68675231',\n",
       " '69956980',\n",
       " '66749246',\n",
       " '70253925',\n",
       " '71851935',\n",
       " '62011444',\n",
       " '68564061',\n",
       " '72244156',\n",
       " '68715062',\n",
       " '72457200',\n",
       " '71430843',\n",
       " '71189966',\n",
       " '71293725',\n",
       " '69802421',\n",
       " '70223375',\n",
       " '71686822',\n",
       " '71188781',\n",
       " '71857143',\n",
       " '71291615',\n",
       " '71851737',\n",
       " '68699701',\n",
       " '67896489',\n",
       " '71293654',\n",
       " '69856091',\n",
       " '69065735',\n",
       " '69685775',\n",
       " '62016897',\n",
       " '67098815',\n",
       " '70676738',\n",
       " '69544219',\n",
       " '68063266',\n",
       " '68695864',\n",
       " '64587110',\n",
       " '68676602',\n",
       " '71561249',\n",
       " '69930907',\n",
       " '68994913',\n",
       " '64602169',\n",
       " '69087918',\n",
       " '66643191',\n",
       " '72661545',\n",
       " '71443726',\n",
       " '69792349',\n",
       " '72479164',\n",
       " '70757997',\n",
       " '69172926',\n",
       " '68242247',\n",
       " '72200044',\n",
       " '69801399',\n",
       " '68714140',\n",
       " '67996688',\n",
       " '67098684',\n",
       " '70436315',\n",
       " '67802489',\n",
       " '72242359',\n",
       " '69962730',\n",
       " '72384220',\n",
       " '68678435',\n",
       " '68683343',\n",
       " '69169496',\n",
       " '72555421',\n",
       " '71240775',\n",
       " '71432341',\n",
       " '68214614',\n",
       " '72460233',\n",
       " '72338560',\n",
       " '67018488',\n",
       " '71708131',\n",
       " '68700672',\n",
       " '71432102',\n",
       " '70253135',\n",
       " '62004211',\n",
       " '68708318',\n",
       " '71903625',\n",
       " '69088253',\n",
       " '67949521',\n",
       " '69688299',\n",
       " '71142126',\n",
       " '69600287',\n",
       " '70159396',\n",
       " '68612091',\n",
       " '70757636',\n",
       " '68622279',\n",
       " '70420139',\n",
       " '71621313',\n",
       " '67099419',\n",
       " '68299652',\n",
       " '68408186',\n",
       " '62017143',\n",
       " '71847666',\n",
       " '68709520',\n",
       " '69228108',\n",
       " '71375118',\n",
       " '68995641',\n",
       " '68802053',\n",
       " '72115771',\n",
       " '72450640',\n",
       " '67931789',\n",
       " '69931161',\n",
       " '69545040',\n",
       " '72447151',\n",
       " '72481557',\n",
       " '71674616',\n",
       " '68608928',\n",
       " '68538230',\n",
       " '69030000',\n",
       " '69073629',\n",
       " '72338070',\n",
       " '68997528',\n",
       " '68691589',\n",
       " '69746362',\n",
       " '71635418',\n",
       " '71428404',\n",
       " '69673592',\n",
       " '68063513',\n",
       " '71186780',\n",
       " '71711622',\n",
       " '71356489',\n",
       " '70656648',\n",
       " '68242598',\n",
       " '69803404',\n",
       " '69937154',\n",
       " '67174811',\n",
       " '69063925',\n",
       " '68684698',\n",
       " '69035657',\n",
       " '68806037',\n",
       " '71139623',\n",
       " '68702096',\n",
       " '68531828',\n",
       " '48844742',\n",
       " '72342158',\n",
       " '71402732',\n",
       " '66426163',\n",
       " '70599043',\n",
       " '66747476',\n",
       " '69568536',\n",
       " '68573837',\n",
       " '70598762',\n",
       " '72441328',\n",
       " '69192492',\n",
       " '69580237',\n",
       " '70016153',\n",
       " '53863788',\n",
       " '68507612',\n",
       " '68508976',\n",
       " '68310427',\n",
       " '72609298',\n",
       " '72609591',\n",
       " '58936930',\n",
       " '69182884',\n",
       " '72627933',\n",
       " '68537806',\n",
       " '70013065',\n",
       " '46629905',\n",
       " '71691899',\n",
       " '70682023',\n",
       " '68560763',\n",
       " '68718213',\n",
       " '68728610',\n",
       " '70016465',\n",
       " '46635135',\n",
       " '71675717',\n",
       " '46627840',\n",
       " '69539327',\n",
       " '69010815',\n",
       " '72226412',\n",
       " '70090631',\n",
       " '54929044',\n",
       " '71295925',\n",
       " '71609787',\n",
       " '46633806',\n",
       " '72339917',\n",
       " '69817467',\n",
       " '70253936',\n",
       " '70763720',\n",
       " '69220730',\n",
       " '70623750',\n",
       " '68564494',\n",
       " '46626933',\n",
       " '70598851',\n",
       " '68559978',\n",
       " '66578075',\n",
       " '69783619',\n",
       " '70763753',\n",
       " '70148800',\n",
       " '69973695',\n",
       " '68510120',\n",
       " '68302335',\n",
       " '68537749',\n",
       " '67959741',\n",
       " '62007842',\n",
       " '68719557',\n",
       " '68560477',\n",
       " '71556854',\n",
       " '69011871',\n",
       " '71335031',\n",
       " '71608168',\n",
       " '70756164',\n",
       " '55400426',\n",
       " '71750535',\n",
       " '70763481',\n",
       " '69196531',\n",
       " '71337749',\n",
       " '69987622',\n",
       " '71233429',\n",
       " '68718817',\n",
       " '72342085',\n",
       " '69615159',\n",
       " '72340106',\n",
       " '60685363',\n",
       " '71080674',\n",
       " '68718720',\n",
       " '62524959',\n",
       " '72702961',\n",
       " '67444373',\n",
       " '72443411',\n",
       " '70474220',\n",
       " '69996401',\n",
       " '71204423',\n",
       " '71402478',\n",
       " '67746089',\n",
       " '71082148',\n",
       " '66952266',\n",
       " '70016152',\n",
       " '68720930',\n",
       " '66544069',\n",
       " '46628059',\n",
       " '72609667',\n",
       " '71230720',\n",
       " '47920414',\n",
       " '69689688',\n",
       " '64805954',\n",
       " '70232739',\n",
       " '71802875',\n",
       " '69686571',\n",
       " '70763867',\n",
       " '59968160',\n",
       " '69199873',\n",
       " '71805092',\n",
       " '70448586',\n",
       " '68507605',\n",
       " '72184995',\n",
       " '71885903',\n",
       " '50882000',\n",
       " '66932711',\n",
       " '68310471',\n",
       " '69688172',\n",
       " '71353597',\n",
       " '51061143',\n",
       " '72184029',\n",
       " '68560905',\n",
       " '71793578',\n",
       " '68310385',\n",
       " '71841735',\n",
       " '70264328',\n",
       " '68720237',\n",
       " '71614229',\n",
       " '69012306',\n",
       " '46632140',\n",
       " '70627602',\n",
       " '69973851',\n",
       " '66601501',\n",
       " '71606900',\n",
       " '46629831',\n",
       " '71903513',\n",
       " '67151783',\n",
       " '71335886',\n",
       " '72692186',\n",
       " '69011089',\n",
       " '71692209',\n",
       " '70265318',\n",
       " '72192734',\n",
       " '68574254',\n",
       " '70014362',\n",
       " '67959409',\n",
       " '68709313',\n",
       " '71109791',\n",
       " '71805339',\n",
       " '71296110',\n",
       " '68537277',\n",
       " '69580390',\n",
       " '72481346',\n",
       " '68731887',\n",
       " '67749541',\n",
       " '71885864',\n",
       " '68061775',\n",
       " '46634833',\n",
       " '72609755',\n",
       " '71602572',\n",
       " '62011450',\n",
       " '69146692',\n",
       " '69817624',\n",
       " '71094924',\n",
       " '72241686',\n",
       " '70692809',\n",
       " '55278133',\n",
       " '71803987',\n",
       " '69568022',\n",
       " '70086531',\n",
       " '72186225',\n",
       " '46627260',\n",
       " '68700336',\n",
       " '69748492',\n",
       " '68372648',\n",
       " '71841765',\n",
       " '72287638',\n",
       " '70205656',\n",
       " '69191349',\n",
       " '56209809',\n",
       " '69768322',\n",
       " '72226795',\n",
       " '66952130',\n",
       " '69266150',\n",
       " '71803856',\n",
       " '71335000',\n",
       " '69119013',\n",
       " '69587191',\n",
       " '72118191',\n",
       " '72694003',\n",
       " '68576341',\n",
       " '71691917',\n",
       " '68728668',\n",
       " '71812575',\n",
       " '71090289',\n",
       " '46629059',\n",
       " '72478300',\n",
       " '69783468',\n",
       " '69551029',\n",
       " '68805556',\n",
       " '69265319',\n",
       " '70256561',\n",
       " '72666862',\n",
       " '66630867',\n",
       " '72453749',\n",
       " '72635560',\n",
       " '71099289',\n",
       " '71818770',\n",
       " '70076682',\n",
       " '72689197',\n",
       " '68218431',\n",
       " '70807997',\n",
       " '69198249',\n",
       " '69079778',\n",
       " '71851898',\n",
       " '71099880',\n",
       " '72485752',\n",
       " '72236089',\n",
       " '71125336',\n",
       " '71619468',\n",
       " '71679611',\n",
       " '69079190',\n",
       " '69213729',\n",
       " '70218883',\n",
       " '69145960',\n",
       " '69536987',\n",
       " '68217600',\n",
       " '69267760',\n",
       " '71631590',\n",
       " '72117596',\n",
       " '70762357',\n",
       " '72444694',\n",
       " '67442211',\n",
       " '70250035',\n",
       " '72454550',\n",
       " '70077718',\n",
       " '71816988',\n",
       " '67333526',\n",
       " '68705166',\n",
       " '69145949',\n",
       " '69083137',\n",
       " '68179675',\n",
       " '72481581',\n",
       " '72634040',\n",
       " '71850659',\n",
       " '71796980',\n",
       " '72485443',\n",
       " '69867890',\n",
       " '69081850',\n",
       " '71367580',\n",
       " '66298393',\n",
       " '67946086',\n",
       " '71125587',\n",
       " '68679476',\n",
       " '71369502',\n",
       " '71856853',\n",
       " '71125819',\n",
       " '68217095',\n",
       " '68546047',\n",
       " '69966873',\n",
       " '71196021',\n",
       " '72404995',\n",
       " '70076688',\n",
       " '69079811',\n",
       " '71369684',\n",
       " '71230837',\n",
       " '67958106',\n",
       " '72443359',\n",
       " '69079850',\n",
       " '72690861',\n",
       " '71685513',\n",
       " '70218831',\n",
       " '69052698',\n",
       " '71199807',\n",
       " '68181436',\n",
       " '64809893',\n",
       " '71215909',\n",
       " '72395107',\n",
       " '69190420',\n",
       " '70675910',\n",
       " '69501426',\n",
       " '68218446',\n",
       " '72337118',\n",
       " '72531481',\n",
       " '66905324',\n",
       " '70162275',\n",
       " '67946221',\n",
       " '67304988',\n",
       " '69079024',\n",
       " '68824328',\n",
       " '72395002',\n",
       " '72444583',\n",
       " '67949291',\n",
       " '70322392',\n",
       " '69966126',\n",
       " '69993139',\n",
       " '70755882',\n",
       " '69669856',\n",
       " '69080771',\n",
       " '70676894',\n",
       " '72238038',\n",
       " '72406398',\n",
       " '72241526',\n",
       " '69267364',\n",
       " '71469076',\n",
       " '66506073',\n",
       " '70607796',\n",
       " '71443055',\n",
       " '67946161',\n",
       " '69171545',\n",
       " '69081099',\n",
       " '72443521',\n",
       " '69848827',\n",
       " '69082147',\n",
       " '68218566',\n",
       " '64144831',\n",
       " '64216173',\n",
       " '70608442',\n",
       " '72427959',\n",
       " '68544610',\n",
       " '70309482',\n",
       " '69551242',\n",
       " '68700091',\n",
       " '72479966',\n",
       " '71186393',\n",
       " '71812293',\n",
       " '69557422',\n",
       " '72405497',\n",
       " '69805343',\n",
       " '62113808',\n",
       " '71224914',\n",
       " '71443077',\n",
       " '68057472',\n",
       " '70677481',\n",
       " '72564385',\n",
       " '72630830',\n",
       " '68704193',\n",
       " '70321511',\n",
       " '69147753',\n",
       " '70077260',\n",
       " '69671196',\n",
       " '72691194',\n",
       " '68707581',\n",
       " '67753890',\n",
       " '72662930',\n",
       " '69805267',\n",
       " '71314005',\n",
       " '68346097',\n",
       " '71821372',\n",
       " '70207759',\n",
       " '69083316',\n",
       " '72351069',\n",
       " '71851119',\n",
       " '72628995',\n",
       " '66981532',\n",
       " '72441022',\n",
       " '72442746',\n",
       " '70218857',\n",
       " '72447529',\n",
       " '72690823',\n",
       " '72690576',\n",
       " '72198584',\n",
       " '71763997',\n",
       " '69080365',\n",
       " '69600129',\n",
       " '69264935',\n",
       " '69084078',\n",
       " '71470776',\n",
       " '72444600',\n",
       " '68712859',\n",
       " '72480999',\n",
       " '66673865',\n",
       " '68548006',\n",
       " '72679817',\n",
       " '68591444',\n",
       " '72351795',\n",
       " '69168938',\n",
       " '72442494',\n",
       " '72452403',\n",
       " '71904521',\n",
       " '68238154',\n",
       " '68293795',\n",
       " '69747537',\n",
       " '72428168',\n",
       " '69776905',\n",
       " '71196096',\n",
       " '69080837',\n",
       " '70104899',\n",
       " '70162126',\n",
       " '71902193',\n",
       " '72697363',\n",
       " '71851279',\n",
       " '72610903',\n",
       " '69249326',\n",
       " '69007802',\n",
       " '69082733',\n",
       " '55409704',\n",
       " '67945529',\n",
       " '71213522',\n",
       " '72485547',\n",
       " '72697019',\n",
       " '69558397',\n",
       " '72243490',\n",
       " '69080968',\n",
       " '72444214',\n",
       " '69080512',\n",
       " '69121415',\n",
       " '69776963',\n",
       " '67441347',\n",
       " '72630989',\n",
       " '69689923',\n",
       " '69250944',\n",
       " '72690626',\n",
       " '72450119',\n",
       " '71820132',\n",
       " '69559906',\n",
       " '71677261',\n",
       " '71292106',\n",
       " '72386497',\n",
       " '69078766',\n",
       " '72427843',\n",
       " '70253617',\n",
       " '72427796',\n",
       " '71125410',\n",
       " '67770798',\n",
       " '69082575',\n",
       " '68849619',\n",
       " '72379491',\n",
       " '71631421']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract webindex from job data\n",
    "\n",
    "# Indicate original data folder\n",
    "original_data_folder = \"data\"\n",
    "\n",
    "# Initiate an empty list to store webindex numbers\n",
    "webindex_numbers = []\n",
    "\n",
    "# Iterate through the original data files and extract webindex\n",
    "for category_folder in os.listdir(original_data_folder):\n",
    "    category_path = os.path.join(original_data_folder, category_folder)\n",
    "    if os.path.isdir(category_path):\n",
    "        for job_file in os.listdir(category_path):\n",
    "            if job_file.startswith(\"Job_\") and job_file.endswith(\".txt\"):\n",
    "                with open(os.path.join(category_path, job_file), \"r\", encoding=\"utf-8\") as f:\n",
    "                    content = f.read()\n",
    "                    \n",
    "                    # Extract the webindex from the original data and remove the newline character\n",
    "                    webindex = content.split(\"Webindex: \")[1].split(\"\\n\")[0]\n",
    "                    \n",
    "                    webindex_numbers.append(webindex)\n",
    "\n",
    "webindex_numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Pre-processing data\n",
    "Perform the required text pre-processing steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin with defining functions for tokenising data and printing stats. Within the tokenising function, we use <span style=\"color: red\"> r\"[a-zA-Z]+(?:[-'][a-zA-Z]+)?\" </span> as a regular expression. We also transform every word into lower-case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to tokenise data\n",
    "\n",
    "def tokenize_data(data_raw):\n",
    "    \"\"\"\n",
    "        This function first convert all words to lowercases, \n",
    "        it then segment the raw review into sentences and tokenize each sentences \n",
    "        and convert the review to a list of tokens.\n",
    "    \"\"\"        \n",
    "    # Convert to lower case\n",
    "    data_lc = data_raw.lower()\n",
    "    \n",
    "    # segament into sentences\n",
    "    sentences = sent_tokenize(data_lc)\n",
    "    \n",
    "    # tokenize each sentence\n",
    "    pattern = r\"[a-zA-Z]+(?:[-'][a-zA-Z]+)?\"\n",
    "    tokenizer = RegexpTokenizer(pattern) \n",
    "    token_lists = [tokenizer.tokenize(sen) for sen in sentences]\n",
    "    \n",
    "    # merge them into a list of tokens\n",
    "    data_tokenised = list(chain.from_iterable(token_lists))\n",
    "    return data_tokenised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to print the current stats\n",
    "\n",
    "def stats_print(data_tk):\n",
    "    words = list(chain.from_iterable(data_tk))\n",
    "    vocab = set(words)\n",
    "    lexical_diversity = len(vocab)/len(words)\n",
    "    print(\"Vocabulary size: \",len(vocab))\n",
    "    print(\"Total number of tokens: \", len(words))\n",
    "    print(\"Lexical diversity: \", lexical_diversity)\n",
    "    print(\"Total number of reviews:\", len(data_tk))\n",
    "    lens = [len(article) for article in data_tk]\n",
    "    print(\"Average review length:\", np.mean(lens))\n",
    "    print(\"Maximun review length:\", np.max(lens))\n",
    "    print(\"Minimun review length:\", np.min(lens))\n",
    "    print(\"Standard deviation of review length:\", np.std(lens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      " Accountant (partqualified) to **** p.a. South East London Our client, a successful manufacturing company has an immediate requirement for an Accountant for permanent role in their modern offices in South East London. The Role: Credit Control Purchase / Sales Ledger Daily collection of debts by phone, letter and email. Handling of ledger accounts Handling disputed accounts and negotiating payment terms Allocating of cash and reconciliation of accounts Adhoc administration duties within the business The Person The ideal candidate will have previous experience in a Credit Control capacity, you will possess exceptional customer service and communication skills together with IT proficiency. You will need to be a part or fully qualified Accountant to be considered for this role \n",
      "\n",
      "Tokenized Data:\n",
      " ['accountant', 'partqualified', 'to', 'p', 'a', 'south', 'east', 'london', 'our', 'client', 'a', 'successful', 'manufacturing', 'company', 'has', 'an', 'immediate', 'requirement', 'for', 'an', 'accountant', 'for', 'permanent', 'role', 'in', 'their', 'modern', 'offices', 'in', 'south', 'east', 'london', 'the', 'role', 'credit', 'control', 'purchase', 'sales', 'ledger', 'daily', 'collection', 'of', 'debts', 'by', 'phone', 'letter', 'and', 'email', 'handling', 'of', 'ledger', 'accounts', 'handling', 'disputed', 'accounts', 'and', 'negotiating', 'payment', 'terms', 'allocating', 'of', 'cash', 'and', 'reconciliation', 'of', 'accounts', 'adhoc', 'administration', 'duties', 'within', 'the', 'business', 'the', 'person', 'the', 'ideal', 'candidate', 'will', 'have', 'previous', 'experience', 'in', 'a', 'credit', 'control', 'capacity', 'you', 'will', 'possess', 'exceptional', 'customer', 'service', 'and', 'communication', 'skills', 'together', 'with', 'it', 'proficiency', 'you', 'will', 'need', 'to', 'be', 'a', 'part', 'or', 'fully', 'qualified', 'accountant', 'to', 'be', 'considered', 'for', 'this', 'role']\n"
     ]
    }
   ],
   "source": [
    "# Tokenise the data and compare the result with the original data\n",
    "\n",
    "data_tk = [tokenize_data(d) for d in descriptions]\n",
    "\n",
    "print(\"Original Data:\\n\",descriptions[emp],'\\n')\n",
    "print(\"Tokenized Data:\\n\",data_tk[emp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size:  9834\n",
      "Total number of tokens:  186952\n",
      "Lexical diversity:  0.052601737344345076\n",
      "Total number of reviews: 776\n",
      "Average review length: 240.91752577319588\n",
      "Maximun review length: 815\n",
      "Minimun review length: 13\n",
      "Standard deviation of review length: 124.97750685071483\n"
     ]
    }
   ],
   "source": [
    "# First check point for overall stats\n",
    "\n",
    "stats_print(data_tk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After tokenising the data, we can now filter out required pre-processing steps:\n",
    "\n",
    "- Remove words with length less than 2\n",
    "- Remove stopwords using the provided stop words list (i.e, stopwords_en.txt)\n",
    "- Remove the words that appear only once in the document collection, based on term frequency\n",
    "- Remove the top 50 most frequent words based on document frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['p',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'c',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 's',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'k',\n",
       " 'k',\n",
       " 's',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'k',\n",
       " 'a',\n",
       " 'b',\n",
       " 'b',\n",
       " 'a',\n",
       " 'b',\n",
       " 'b',\n",
       " 'a',\n",
       " 'a',\n",
       " 'b',\n",
       " 'b',\n",
       " 's',\n",
       " 's',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'k',\n",
       " 'a',\n",
       " 'a',\n",
       " 's',\n",
       " 'a',\n",
       " 'd',\n",
       " 'd',\n",
       " 'a',\n",
       " 's',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'k',\n",
       " 'a',\n",
       " 's',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'c',\n",
       " 'k',\n",
       " 'a',\n",
       " 'a',\n",
       " 'k',\n",
       " 'a',\n",
       " 'a',\n",
       " 'k',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'm',\n",
       " 'm',\n",
       " 'm',\n",
       " 'm',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 's',\n",
       " 's',\n",
       " 'a',\n",
       " 's',\n",
       " 'a',\n",
       " 's',\n",
       " 'a',\n",
       " 's',\n",
       " 'a',\n",
       " 's',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 's',\n",
       " 's',\n",
       " 's',\n",
       " 'a',\n",
       " 'a',\n",
       " 's',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'k',\n",
       " 'a',\n",
       " 'p',\n",
       " 'l',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'm',\n",
       " 's',\n",
       " 's',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 't',\n",
       " 't',\n",
       " 'a',\n",
       " 's',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'c',\n",
       " 'k',\n",
       " 'i',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'c',\n",
       " 'k',\n",
       " 'n',\n",
       " 'a',\n",
       " 'i',\n",
       " 'i',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'n',\n",
       " 'a',\n",
       " 'j',\n",
       " 'n',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 's',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'g',\n",
       " 'p',\n",
       " 'h',\n",
       " 'p',\n",
       " 'h',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'k',\n",
       " 'k',\n",
       " 'k',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'b',\n",
       " 'b',\n",
       " 'a',\n",
       " 'a',\n",
       " 'k',\n",
       " 'k',\n",
       " 'k',\n",
       " 'a',\n",
       " 'a',\n",
       " 'b',\n",
       " 'b',\n",
       " 'a',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'n',\n",
       " 'a',\n",
       " 'g',\n",
       " 's',\n",
       " 'a',\n",
       " 'n',\n",
       " 'a',\n",
       " 'n',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 's',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'a',\n",
       " 'a',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 's',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 's',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 's',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 's',\n",
       " 's',\n",
       " 's',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 's',\n",
       " 's',\n",
       " 'a',\n",
       " 's',\n",
       " 's',\n",
       " 's',\n",
       " 's',\n",
       " 's',\n",
       " 's',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'c',\n",
       " 'g',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'p',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'p',\n",
       " 'l',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 's',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'k',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'b',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'm',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'i',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'b',\n",
       " 'b',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 's',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'k',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 's',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 's',\n",
       " 's',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'c',\n",
       " 's',\n",
       " 'a',\n",
       " 'm',\n",
       " 'm',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'c',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'p',\n",
       " 'h',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'k',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'k',\n",
       " 'k',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'p',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'k',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'k',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'o',\n",
       " 'o',\n",
       " 'a',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 's',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'a',\n",
       " 'o',\n",
       " 'a',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 't',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'k',\n",
       " 'k',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'j',\n",
       " 'k',\n",
       " 'i',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'h',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 's',\n",
       " 'h',\n",
       " 'i',\n",
       " 't',\n",
       " 'i',\n",
       " 'i',\n",
       " 'i',\n",
       " 't',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 's',\n",
       " 'a',\n",
       " 'a',\n",
       " 's',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 's',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'i',\n",
       " 'e',\n",
       " 'a',\n",
       " 'm',\n",
       " 'm',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 's',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'd',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'k',\n",
       " 'k',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'k',\n",
       " 'k',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 's',\n",
       " 't',\n",
       " 'c',\n",
       " 's',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'i',\n",
       " 'a',\n",
       " 'i',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'k',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 's',\n",
       " 's',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'k',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'u',\n",
       " 'u',\n",
       " 'k',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'i',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'h',\n",
       " 'a',\n",
       " 'a',\n",
       " 'h',\n",
       " 's',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'd',\n",
       " 'a',\n",
       " 'e',\n",
       " 'k',\n",
       " 'k',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'k',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'n',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'k',\n",
       " 'm',\n",
       " 'e',\n",
       " 'k',\n",
       " 'm',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 's',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 's',\n",
       " 'r',\n",
       " 'd',\n",
       " 'a',\n",
       " 'a',\n",
       " 'r',\n",
       " 'd',\n",
       " 'k',\n",
       " 'a',\n",
       " 'a',\n",
       " 'm',\n",
       " 'e',\n",
       " 'k',\n",
       " 'm',\n",
       " 'm',\n",
       " 'e',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'm',\n",
       " 'e',\n",
       " 'd',\n",
       " 'b',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'k',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 's',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'c',\n",
       " 'k',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 's',\n",
       " 'a',\n",
       " 'a',\n",
       " ...]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check all the single character tokens\n",
    "\n",
    "# Create a list of single character token for each review\n",
    "st_list = [[w for w in words if len(w) < 2 ] for words in data_tk] \n",
    "\n",
    "# Merge them together in one list\n",
    "list(chain.from_iterable(st_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized Data with at least 2 characters:\n",
      " ['accountant', 'partqualified', 'to', 'south', 'east', 'london', 'our', 'client', 'successful', 'manufacturing', 'company', 'has', 'an', 'immediate', 'requirement', 'for', 'an', 'accountant', 'for', 'permanent', 'role', 'in', 'their', 'modern', 'offices', 'in', 'south', 'east', 'london', 'the', 'role', 'credit', 'control', 'purchase', 'sales', 'ledger', 'daily', 'collection', 'of', 'debts', 'by', 'phone', 'letter', 'and', 'email', 'handling', 'of', 'ledger', 'accounts', 'handling', 'disputed', 'accounts', 'and', 'negotiating', 'payment', 'terms', 'allocating', 'of', 'cash', 'and', 'reconciliation', 'of', 'accounts', 'adhoc', 'administration', 'duties', 'within', 'the', 'business', 'the', 'person', 'the', 'ideal', 'candidate', 'will', 'have', 'previous', 'experience', 'in', 'credit', 'control', 'capacity', 'you', 'will', 'possess', 'exceptional', 'customer', 'service', 'and', 'communication', 'skills', 'together', 'with', 'it', 'proficiency', 'you', 'will', 'need', 'to', 'be', 'part', 'or', 'fully', 'qualified', 'accountant', 'to', 'be', 'considered', 'for', 'this', 'role']\n"
     ]
    }
   ],
   "source": [
    "# Filter out single character tokens\n",
    "data_tk = [[w for w in words if len(w) >=2] for words in data_tk]\n",
    "\n",
    "print(\"Tokenized Data with at least 2 characters:\\n\", data_tk[emp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size:  9808\n",
      "Total number of tokens:  180913\n",
      "Lexical diversity:  0.05421390392066905\n",
      "Total number of reviews: 776\n",
      "Average review length: 233.13530927835052\n",
      "Maximun review length: 795\n",
      "Minimun review length: 13\n",
      "Standard deviation of review length: 121.6048654015839\n"
     ]
    }
   ],
   "source": [
    "# Check stats after eliminating single character tokens\n",
    "\n",
    "stats_print(data_tk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " \"a's\",\n",
       " 'able',\n",
       " 'about',\n",
       " 'above',\n",
       " 'according',\n",
       " 'accordingly',\n",
       " 'across',\n",
       " 'actually',\n",
       " 'after',\n",
       " 'afterwards',\n",
       " 'again',\n",
       " 'against',\n",
       " \"ain't\",\n",
       " 'all',\n",
       " 'allow',\n",
       " 'allows',\n",
       " 'almost',\n",
       " 'alone',\n",
       " 'along',\n",
       " 'already',\n",
       " 'also',\n",
       " 'although',\n",
       " 'always',\n",
       " 'am',\n",
       " 'among',\n",
       " 'amongst',\n",
       " 'an',\n",
       " 'and',\n",
       " 'another',\n",
       " 'any',\n",
       " 'anybody',\n",
       " 'anyhow',\n",
       " 'anyone',\n",
       " 'anything',\n",
       " 'anyway',\n",
       " 'anyways',\n",
       " 'anywhere',\n",
       " 'apart',\n",
       " 'appear',\n",
       " 'appreciate',\n",
       " 'appropriate',\n",
       " 'are',\n",
       " \"aren't\",\n",
       " 'around',\n",
       " 'as',\n",
       " 'aside',\n",
       " 'ask',\n",
       " 'asking',\n",
       " 'associated',\n",
       " 'at',\n",
       " 'available',\n",
       " 'away',\n",
       " 'awfully',\n",
       " 'b',\n",
       " 'be',\n",
       " 'became',\n",
       " 'because',\n",
       " 'become',\n",
       " 'becomes',\n",
       " 'becoming',\n",
       " 'been',\n",
       " 'before',\n",
       " 'beforehand',\n",
       " 'behind',\n",
       " 'being',\n",
       " 'believe',\n",
       " 'below',\n",
       " 'beside',\n",
       " 'besides',\n",
       " 'best',\n",
       " 'better',\n",
       " 'between',\n",
       " 'beyond',\n",
       " 'both',\n",
       " 'brief',\n",
       " 'but',\n",
       " 'by',\n",
       " 'c',\n",
       " \"c'mon\",\n",
       " \"c's\",\n",
       " 'came',\n",
       " 'can',\n",
       " \"can't\",\n",
       " 'cannot',\n",
       " 'cant',\n",
       " 'cause',\n",
       " 'causes',\n",
       " 'certain',\n",
       " 'certainly',\n",
       " 'changes',\n",
       " 'clearly',\n",
       " 'co',\n",
       " 'com',\n",
       " 'come',\n",
       " 'comes',\n",
       " 'concerning',\n",
       " 'consequently',\n",
       " 'consider',\n",
       " 'considering',\n",
       " 'contain',\n",
       " 'containing',\n",
       " 'contains',\n",
       " 'corresponding',\n",
       " 'could',\n",
       " \"couldn't\",\n",
       " 'course',\n",
       " 'currently',\n",
       " 'd',\n",
       " 'definitely',\n",
       " 'described',\n",
       " 'despite',\n",
       " 'did',\n",
       " \"didn't\",\n",
       " 'different',\n",
       " 'do',\n",
       " 'does',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " \"don't\",\n",
       " 'done',\n",
       " 'down',\n",
       " 'downwards',\n",
       " 'during',\n",
       " 'e',\n",
       " 'each',\n",
       " 'edu',\n",
       " 'eg',\n",
       " 'eight',\n",
       " 'either',\n",
       " 'else',\n",
       " 'elsewhere',\n",
       " 'enough',\n",
       " 'entirely',\n",
       " 'especially',\n",
       " 'et',\n",
       " 'etc',\n",
       " 'even',\n",
       " 'ever',\n",
       " 'every',\n",
       " 'everybody',\n",
       " 'everyone',\n",
       " 'everything',\n",
       " 'everywhere',\n",
       " 'ex',\n",
       " 'exactly',\n",
       " 'example',\n",
       " 'except',\n",
       " 'f',\n",
       " 'far',\n",
       " 'few',\n",
       " 'fifth',\n",
       " 'first',\n",
       " 'five',\n",
       " 'followed',\n",
       " 'following',\n",
       " 'follows',\n",
       " 'for',\n",
       " 'former',\n",
       " 'formerly',\n",
       " 'forth',\n",
       " 'four',\n",
       " 'from',\n",
       " 'further',\n",
       " 'furthermore',\n",
       " 'g',\n",
       " 'get',\n",
       " 'gets',\n",
       " 'getting',\n",
       " 'given',\n",
       " 'gives',\n",
       " 'go',\n",
       " 'goes',\n",
       " 'going',\n",
       " 'gone',\n",
       " 'got',\n",
       " 'gotten',\n",
       " 'greetings',\n",
       " 'h',\n",
       " 'had',\n",
       " \"hadn't\",\n",
       " 'happens',\n",
       " 'hardly',\n",
       " 'has',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " \"he's\",\n",
       " 'hello',\n",
       " 'help',\n",
       " 'hence',\n",
       " 'her',\n",
       " 'here',\n",
       " \"here's\",\n",
       " 'hereafter',\n",
       " 'hereby',\n",
       " 'herein',\n",
       " 'hereupon',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'hi',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'hither',\n",
       " 'hopefully',\n",
       " 'how',\n",
       " 'howbeit',\n",
       " 'however',\n",
       " 'i',\n",
       " \"i'd\",\n",
       " \"i'll\",\n",
       " \"i'm\",\n",
       " \"i've\",\n",
       " 'ie',\n",
       " 'if',\n",
       " 'ignored',\n",
       " 'immediate',\n",
       " 'in',\n",
       " 'inasmuch',\n",
       " 'inc',\n",
       " 'indeed',\n",
       " 'indicate',\n",
       " 'indicated',\n",
       " 'indicates',\n",
       " 'inner',\n",
       " 'insofar',\n",
       " 'instead',\n",
       " 'into',\n",
       " 'inward',\n",
       " 'is',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it'd\",\n",
       " \"it'll\",\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'j',\n",
       " 'just',\n",
       " 'k',\n",
       " 'keep',\n",
       " 'keeps',\n",
       " 'kept',\n",
       " 'know',\n",
       " 'known',\n",
       " 'knows',\n",
       " 'l',\n",
       " 'last',\n",
       " 'lately',\n",
       " 'later',\n",
       " 'latter',\n",
       " 'latterly',\n",
       " 'least',\n",
       " 'less',\n",
       " 'lest',\n",
       " 'let',\n",
       " \"let's\",\n",
       " 'like',\n",
       " 'liked',\n",
       " 'likely',\n",
       " 'little',\n",
       " 'look',\n",
       " 'looking',\n",
       " 'looks',\n",
       " 'ltd',\n",
       " 'm',\n",
       " 'mainly',\n",
       " 'many',\n",
       " 'may',\n",
       " 'maybe',\n",
       " 'me',\n",
       " 'mean',\n",
       " 'meanwhile',\n",
       " 'merely',\n",
       " 'might',\n",
       " 'more',\n",
       " 'moreover',\n",
       " 'most',\n",
       " 'mostly',\n",
       " 'much',\n",
       " 'must',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'n',\n",
       " 'name',\n",
       " 'namely',\n",
       " 'nd',\n",
       " 'near',\n",
       " 'nearly',\n",
       " 'necessary',\n",
       " 'need',\n",
       " 'needs',\n",
       " 'neither',\n",
       " 'never',\n",
       " 'nevertheless',\n",
       " 'new',\n",
       " 'next',\n",
       " 'nine',\n",
       " 'no',\n",
       " 'nobody',\n",
       " 'non',\n",
       " 'none',\n",
       " 'noone',\n",
       " 'nor',\n",
       " 'normally',\n",
       " 'not',\n",
       " 'nothing',\n",
       " 'novel',\n",
       " 'now',\n",
       " 'nowhere',\n",
       " 'o',\n",
       " 'obviously',\n",
       " 'of',\n",
       " 'off',\n",
       " 'often',\n",
       " 'oh',\n",
       " 'ok',\n",
       " 'okay',\n",
       " 'old',\n",
       " 'on',\n",
       " 'once',\n",
       " 'one',\n",
       " 'ones',\n",
       " 'only',\n",
       " 'onto',\n",
       " 'or',\n",
       " 'other',\n",
       " 'others',\n",
       " 'otherwise',\n",
       " 'ought',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'outside',\n",
       " 'over',\n",
       " 'overall',\n",
       " 'own',\n",
       " 'p',\n",
       " 'particular',\n",
       " 'particularly',\n",
       " 'per',\n",
       " 'perhaps',\n",
       " 'placed',\n",
       " 'please',\n",
       " 'plus',\n",
       " 'possible',\n",
       " 'presumably',\n",
       " 'probably',\n",
       " 'provides',\n",
       " 'q',\n",
       " 'que',\n",
       " 'quite',\n",
       " 'qv',\n",
       " 'r',\n",
       " 'rather',\n",
       " 'rd',\n",
       " 're',\n",
       " 'really',\n",
       " 'reasonably',\n",
       " 'regarding',\n",
       " 'regardless',\n",
       " 'regards',\n",
       " 'relatively',\n",
       " 'respectively',\n",
       " 'right',\n",
       " 's',\n",
       " 'said',\n",
       " 'same',\n",
       " 'saw',\n",
       " 'say',\n",
       " 'saying',\n",
       " 'says',\n",
       " 'second',\n",
       " 'secondly',\n",
       " 'see',\n",
       " 'seeing',\n",
       " 'seem',\n",
       " 'seemed',\n",
       " 'seeming',\n",
       " 'seems',\n",
       " 'seen',\n",
       " 'self',\n",
       " 'selves',\n",
       " 'sensible',\n",
       " 'sent',\n",
       " 'serious',\n",
       " 'seriously',\n",
       " 'seven',\n",
       " 'several',\n",
       " 'shall',\n",
       " 'she',\n",
       " 'should',\n",
       " \"shouldn't\",\n",
       " 'since',\n",
       " 'six',\n",
       " 'so',\n",
       " 'some',\n",
       " 'somebody',\n",
       " 'somehow',\n",
       " 'someone',\n",
       " 'something',\n",
       " 'sometime',\n",
       " 'sometimes',\n",
       " 'somewhat',\n",
       " 'somewhere',\n",
       " 'soon',\n",
       " 'sorry',\n",
       " 'specified',\n",
       " 'specify',\n",
       " 'specifying',\n",
       " 'still',\n",
       " 'sub',\n",
       " 'such',\n",
       " 'sup',\n",
       " 'sure',\n",
       " 't',\n",
       " \"t's\",\n",
       " 'take',\n",
       " 'taken',\n",
       " 'tell',\n",
       " 'tends',\n",
       " 'th',\n",
       " 'than',\n",
       " 'thank',\n",
       " 'thanks',\n",
       " 'thanx',\n",
       " 'that',\n",
       " \"that's\",\n",
       " 'thats',\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'thence',\n",
       " 'there',\n",
       " \"there's\",\n",
       " 'thereafter',\n",
       " 'thereby',\n",
       " 'therefore',\n",
       " 'therein',\n",
       " 'theres',\n",
       " 'thereupon',\n",
       " 'these',\n",
       " 'they',\n",
       " \"they'd\",\n",
       " \"they'll\",\n",
       " \"they're\",\n",
       " \"they've\",\n",
       " 'think',\n",
       " 'third',\n",
       " 'this',\n",
       " 'thorough',\n",
       " 'thoroughly',\n",
       " 'those',\n",
       " 'though',\n",
       " 'three',\n",
       " 'through',\n",
       " 'throughout',\n",
       " 'thru',\n",
       " 'thus',\n",
       " 'to',\n",
       " 'together',\n",
       " 'too',\n",
       " 'took',\n",
       " 'toward',\n",
       " 'towards',\n",
       " 'tried',\n",
       " 'tries',\n",
       " 'truly',\n",
       " 'try',\n",
       " 'trying',\n",
       " 'twice',\n",
       " 'two',\n",
       " 'u',\n",
       " 'un',\n",
       " 'under',\n",
       " 'unfortunately',\n",
       " 'unless',\n",
       " 'unlikely',\n",
       " 'until',\n",
       " 'unto',\n",
       " 'up',\n",
       " 'upon',\n",
       " 'us',\n",
       " 'use',\n",
       " 'used',\n",
       " 'useful',\n",
       " 'uses',\n",
       " 'using',\n",
       " 'usually',\n",
       " 'uucp',\n",
       " 'v',\n",
       " 'value',\n",
       " 'various',\n",
       " 'very',\n",
       " 'via',\n",
       " 'viz',\n",
       " 'vs',\n",
       " 'w',\n",
       " 'want',\n",
       " 'wants',\n",
       " 'was',\n",
       " \"wasn't\",\n",
       " 'way',\n",
       " 'we',\n",
       " \"we'd\",\n",
       " \"we'll\",\n",
       " \"we're\",\n",
       " \"we've\",\n",
       " 'welcome',\n",
       " 'well',\n",
       " 'went',\n",
       " 'were',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " \"what's\",\n",
       " 'whatever',\n",
       " 'when',\n",
       " 'whence',\n",
       " 'whenever',\n",
       " 'where',\n",
       " \"where's\",\n",
       " 'whereafter',\n",
       " 'whereas',\n",
       " 'whereby',\n",
       " 'wherein',\n",
       " 'whereupon',\n",
       " 'wherever',\n",
       " 'whether',\n",
       " 'which',\n",
       " 'while',\n",
       " 'whither',\n",
       " 'who',\n",
       " \"who's\",\n",
       " 'whoever',\n",
       " 'whole',\n",
       " 'whom',\n",
       " 'whose',\n",
       " 'why',\n",
       " 'will',\n",
       " 'willing',\n",
       " 'wish',\n",
       " 'with',\n",
       " 'within',\n",
       " 'without',\n",
       " \"won't\",\n",
       " 'wonder',\n",
       " 'would',\n",
       " \"wouldn't\",\n",
       " 'x',\n",
       " 'y',\n",
       " 'yes',\n",
       " 'yet',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'z',\n",
       " 'zero'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import stop words from the required file\n",
    "\n",
    "stopwords_file = \"stopwords_en.txt\"\n",
    "with open(stopwords_file, 'r') as f:\n",
    "    stop_words = set(f.read().split())\n",
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized Data excluding stop words:\n",
      " ['accountant', 'partqualified', 'south', 'east', 'london', 'client', 'successful', 'manufacturing', 'company', 'requirement', 'accountant', 'permanent', 'role', 'modern', 'offices', 'south', 'east', 'london', 'role', 'credit', 'control', 'purchase', 'sales', 'ledger', 'daily', 'collection', 'debts', 'phone', 'letter', 'email', 'handling', 'ledger', 'accounts', 'handling', 'disputed', 'accounts', 'negotiating', 'payment', 'terms', 'allocating', 'cash', 'reconciliation', 'accounts', 'adhoc', 'administration', 'duties', 'business', 'person', 'ideal', 'candidate', 'previous', 'experience', 'credit', 'control', 'capacity', 'possess', 'exceptional', 'customer', 'service', 'communication', 'skills', 'proficiency', 'part', 'fully', 'qualified', 'accountant', 'considered', 'role']\n"
     ]
    }
   ],
   "source": [
    "# Filter out stop words\n",
    "\n",
    "data_tk = [[w for w in words if w not in stop_words] for words in data_tk]\n",
    "\n",
    "print(\"Tokenized Data excluding stop words:\\n\", data_tk[emp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size:  9404\n",
      "Total number of tokens:  107161\n",
      "Lexical diversity:  0.0877558066834016\n",
      "Total number of reviews: 776\n",
      "Average review length: 138.09407216494844\n",
      "Maximun review length: 487\n",
      "Minimun review length: 12\n",
      "Standard deviation of review length: 73.07847897002313\n"
     ]
    }
   ],
   "source": [
    "# Check stats after eliminating stop words\n",
    "\n",
    "stats_print(data_tk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'accountant': 53,\n",
       "         'partqualified': 5,\n",
       "         'south': 72,\n",
       "         'east': 78,\n",
       "         'london': 175,\n",
       "         'client': 594,\n",
       "         'successful': 340,\n",
       "         'manufacturing': 159,\n",
       "         'company': 614,\n",
       "         'requirement': 29,\n",
       "         'permanent': 147,\n",
       "         'role': 946,\n",
       "         'modern': 21,\n",
       "         'offices': 41,\n",
       "         'credit': 37,\n",
       "         'control': 179,\n",
       "         'purchase': 29,\n",
       "         'sales': 1030,\n",
       "         'ledger': 37,\n",
       "         'daily': 62,\n",
       "         'collection': 13,\n",
       "         'debts': 2,\n",
       "         'phone': 33,\n",
       "         'letter': 25,\n",
       "         'email': 144,\n",
       "         'handling': 33,\n",
       "         'accounts': 153,\n",
       "         'disputed': 1,\n",
       "         'negotiating': 7,\n",
       "         'payment': 22,\n",
       "         'terms': 26,\n",
       "         'allocating': 1,\n",
       "         'cash': 47,\n",
       "         'reconciliation': 15,\n",
       "         'adhoc': 18,\n",
       "         'administration': 72,\n",
       "         'duties': 147,\n",
       "         'business': 832,\n",
       "         'person': 99,\n",
       "         'ideal': 102,\n",
       "         'candidate': 319,\n",
       "         'previous': 142,\n",
       "         'experience': 1276,\n",
       "         'capacity': 20,\n",
       "         'possess': 49,\n",
       "         'exceptional': 26,\n",
       "         'customer': 335,\n",
       "         'service': 481,\n",
       "         'communication': 209,\n",
       "         'skills': 669,\n",
       "         'proficiency': 1,\n",
       "         'part': 209,\n",
       "         'fully': 59,\n",
       "         'qualified': 181,\n",
       "         'considered': 80,\n",
       "         'leading': 289,\n",
       "         'hedge': 4,\n",
       "         'funds': 8,\n",
       "         'recruiting': 80,\n",
       "         'fund': 14,\n",
       "         'join': 302,\n",
       "         'team': 789,\n",
       "         'paying': 15,\n",
       "         'outstanding': 41,\n",
       "         'benefits': 239,\n",
       "         'based': 376,\n",
       "         'west': 54,\n",
       "         'end': 61,\n",
       "         'report': 47,\n",
       "         'head': 54,\n",
       "         'accounting': 59,\n",
       "         'work': 861,\n",
       "         'number': 88,\n",
       "         'accountants': 12,\n",
       "         'senior': 200,\n",
       "         'responsible': 217,\n",
       "         'dealing': 53,\n",
       "         'equities': 1,\n",
       "         'equity': 15,\n",
       "         'related': 61,\n",
       "         'products': 187,\n",
       "         'involves': 21,\n",
       "         'aspects': 56,\n",
       "         'preparation': 51,\n",
       "         'journal': 3,\n",
       "         'voucher': 5,\n",
       "         'entries': 4,\n",
       "         'nav': 5,\n",
       "         'review': 69,\n",
       "         'reviews': 43,\n",
       "         'securities': 16,\n",
       "         'trade': 19,\n",
       "         'input': 23,\n",
       "         'pricing': 34,\n",
       "         'fluctuations': 1,\n",
       "         'financial': 279,\n",
       "         'statements': 16,\n",
       "         'exciting': 108,\n",
       "         'opportunity': 372,\n",
       "         'arisen': 59,\n",
       "         'establish': 30,\n",
       "         'provider': 61,\n",
       "         'elderly': 55,\n",
       "         'care': 675,\n",
       "         'services': 369,\n",
       "         'deputy': 46,\n",
       "         'home': 291,\n",
       "         'manager': 519,\n",
       "         'support': 501,\n",
       "         'day': 158,\n",
       "         'running': 33,\n",
       "         'passion': 31,\n",
       "         'working': 719,\n",
       "         'sector': 133,\n",
       "         'proven': 114,\n",
       "         'job': 688,\n",
       "         'description': 42,\n",
       "         'assist': 131,\n",
       "         'registered': 166,\n",
       "         'management': 572,\n",
       "         'responsibility': 103,\n",
       "         'absence': 16,\n",
       "         'requirements': 239,\n",
       "         'ensure': 290,\n",
       "         'high': 309,\n",
       "         'standards': 144,\n",
       "         'delivered': 26,\n",
       "         'meet': 87,\n",
       "         'individual': 132,\n",
       "         'residents': 74,\n",
       "         'healthcare': 101,\n",
       "         'met': 27,\n",
       "         'liaising': 38,\n",
       "         'gp': 20,\n",
       "         'district': 5,\n",
       "         'nurses': 76,\n",
       "         'chiropodists': 1,\n",
       "         'supervision': 45,\n",
       "         'lead': 97,\n",
       "         'manage': 180,\n",
       "         'develop': 206,\n",
       "         'staff': 271,\n",
       "         'qualifications': 111,\n",
       "         'nvq': 29,\n",
       "         'level': 221,\n",
       "         'residential': 46,\n",
       "         'older': 23,\n",
       "         'people': 220,\n",
       "         'supervisory': 16,\n",
       "         'flexible': 100,\n",
       "         'shift': 88,\n",
       "         'pattern': 17,\n",
       "         'originally': 191,\n",
       "         'posted': 193,\n",
       "         'www': 250,\n",
       "         'totaljobs': 165,\n",
       "         'jobseeking': 191,\n",
       "         'deputyhomemanager': 1,\n",
       "         'onetwotrade': 1,\n",
       "         'expanding': 51,\n",
       "         'junior': 36,\n",
       "         'trainee': 15,\n",
       "         'brokers': 6,\n",
       "         'city': 37,\n",
       "         'trading': 22,\n",
       "         'floor': 12,\n",
       "         'open': 22,\n",
       "         'close': 50,\n",
       "         'clients': 310,\n",
       "         'required': 399,\n",
       "         'contact': 233,\n",
       "         'worldwide': 28,\n",
       "         'candidates': 233,\n",
       "         'demonstrate': 89,\n",
       "         'structured': 22,\n",
       "         'approach': 90,\n",
       "         'show': 11,\n",
       "         'genuine': 22,\n",
       "         'interest': 48,\n",
       "         'finance': 121,\n",
       "         'investments': 11,\n",
       "         'portfolio': 57,\n",
       "         'activities': 91,\n",
       "         'cold': 27,\n",
       "         'calling': 31,\n",
       "         'require': 57,\n",
       "         'ambitious': 46,\n",
       "         'genuinely': 4,\n",
       "         'dynamic': 52,\n",
       "         'rgn': 93,\n",
       "         'hospitals': 16,\n",
       "         'fulltime': 8,\n",
       "         'timehours': 1,\n",
       "         'swiis': 4,\n",
       "         'hour': 78,\n",
       "         'dependent': 25,\n",
       "         'banding': 1,\n",
       "         'bonus': 103,\n",
       "         'hours': 188,\n",
       "         'referafriend': 1,\n",
       "         'free': 51,\n",
       "         'crb': 37,\n",
       "         'immunisation': 1,\n",
       "         'uniform': 9,\n",
       "         'training': 338,\n",
       "         'ongoing': 63,\n",
       "         'professional': 211,\n",
       "         'development': 431,\n",
       "         'excellent': 455,\n",
       "         'outofhours': 1,\n",
       "         'urgently': 9,\n",
       "         'requires': 50,\n",
       "         'experienced': 202,\n",
       "         'rgns': 2,\n",
       "         'hospital': 46,\n",
       "         'roles': 46,\n",
       "         'penarth': 1,\n",
       "         'temporary': 57,\n",
       "         'positions': 46,\n",
       "         'range': 193,\n",
       "         'shifts': 49,\n",
       "         'short': 26,\n",
       "         'longerterm': 4,\n",
       "         'projects': 158,\n",
       "         'year': 93,\n",
       "         'paid': 41,\n",
       "         'postqualification': 1,\n",
       "         'nursing': 228,\n",
       "         'relevant': 158,\n",
       "         'setting': 36,\n",
       "         'understanding': 152,\n",
       "         'knowledge': 349,\n",
       "         'issues': 80,\n",
       "         'faced': 1,\n",
       "         'users': 61,\n",
       "         'commitment': 34,\n",
       "         'wellbeing': 8,\n",
       "         'dedication': 11,\n",
       "         'continued': 26,\n",
       "         'personal': 103,\n",
       "         'submit': 23,\n",
       "         'comprehensive': 35,\n",
       "         'uptodate': 11,\n",
       "         'cv': 253,\n",
       "         'detailing': 3,\n",
       "         'full': 263,\n",
       "         'employment': 225,\n",
       "         'study': 18,\n",
       "         'history': 20,\n",
       "         'incomplete': 2,\n",
       "         'cvs': 10,\n",
       "         'result': 15,\n",
       "         'delays': 3,\n",
       "         'processing': 64,\n",
       "         'registration': 42,\n",
       "         'interim': 9,\n",
       "         'contract': 134,\n",
       "         'recruitment': 335,\n",
       "         'acts': 23,\n",
       "         'agency': 169,\n",
       "         'relation': 65,\n",
       "         'vacancies': 59,\n",
       "         'equal': 57,\n",
       "         'opportunities': 238,\n",
       "         'employer': 65,\n",
       "         'due': 96,\n",
       "         'volume': 56,\n",
       "         'applicants': 109,\n",
       "         'received': 19,\n",
       "         'response': 22,\n",
       "         'days': 173,\n",
       "         'assume': 20,\n",
       "         'application': 148,\n",
       "         'conditions': 33,\n",
       "         'apply': 349,\n",
       "         'bonuses': 18,\n",
       "         'production': 122,\n",
       "         'coordinator': 28,\n",
       "         'sandbach': 2,\n",
       "         'salary': 322,\n",
       "         'pound': 39,\n",
       "         'ndash': 5,\n",
       "         'rsquo': 6,\n",
       "         'experts': 11,\n",
       "         'supplying': 8,\n",
       "         'tailored': 15,\n",
       "         'refrigeration': 7,\n",
       "         'solutions': 165,\n",
       "         'niche': 10,\n",
       "         'markets': 56,\n",
       "         'supermarkets': 2,\n",
       "         'industrial': 39,\n",
       "         'plants': 2,\n",
       "         'established': 98,\n",
       "         'years': 172,\n",
       "         'contracting': 3,\n",
       "         'past': 14,\n",
       "         'set': 67,\n",
       "         'expand': 19,\n",
       "         'nbsp': 189,\n",
       "         'restructuring': 4,\n",
       "         'small': 66,\n",
       "         'friendly': 48,\n",
       "         'administrative': 20,\n",
       "         'tasks': 45,\n",
       "         'relating': 23,\n",
       "         'targets': 88,\n",
       "         'order': 82,\n",
       "         'crm': 5,\n",
       "         'system': 95,\n",
       "         'include': 215,\n",
       "         'regular': 48,\n",
       "         'telesales': 42,\n",
       "         'build': 79,\n",
       "         'strong': 299,\n",
       "         'relationships': 116,\n",
       "         'suppliers': 38,\n",
       "         'raising': 4,\n",
       "         'orders': 22,\n",
       "         'prioritising': 6,\n",
       "         'load': 7,\n",
       "         'answering': 3,\n",
       "         'queries': 46,\n",
       "         'arriving': 1,\n",
       "         'telephone': 60,\n",
       "         'facsimile': 1,\n",
       "         'internal': 141,\n",
       "         'external': 66,\n",
       "         'research': 51,\n",
       "         'retrieve': 1,\n",
       "         'information': 231,\n",
       "         'awareness': 40,\n",
       "         'stock': 22,\n",
       "         'procedures': 112,\n",
       "         'audits': 29,\n",
       "         'perform': 35,\n",
       "         'clerical': 2,\n",
       "         'needed': 22,\n",
       "         'filing': 5,\n",
       "         'photocopying': 1,\n",
       "         'collating': 1,\n",
       "         'ability': 301,\n",
       "         'questions': 8,\n",
       "         'ascertain': 4,\n",
       "         'potential': 77,\n",
       "         \"customer's\": 5,\n",
       "         'maintaining': 59,\n",
       "         'relationship': 34,\n",
       "         'software': 179,\n",
       "         'excel': 62,\n",
       "         'spread': 2,\n",
       "         'sheets': 6,\n",
       "         'general': 122,\n",
       "         'reporting': 158,\n",
       "         'arrange': 8,\n",
       "         'national': 56,\n",
       "         'international': 91,\n",
       "         'courier': 14,\n",
       "         'shipments': 5,\n",
       "         'escalate': 4,\n",
       "         'delivery': 83,\n",
       "         'returns': 19,\n",
       "         'files': 8,\n",
       "         'records': 53,\n",
       "         'updated': 8,\n",
       "         'maintain': 142,\n",
       "         'confidentiality': 14,\n",
       "         'times': 52,\n",
       "         'technical': 217,\n",
       "         'electronic': 52,\n",
       "         'components': 25,\n",
       "         'basic': 140,\n",
       "         'outlook': 18,\n",
       "         'windows': 8,\n",
       "         'xp': 1,\n",
       "         'office': 177,\n",
       "         'solvitt': 1,\n",
       "         'verbal': 41,\n",
       "         'listening': 11,\n",
       "         'express': 9,\n",
       "         'thoughts': 1,\n",
       "         'positive': 31,\n",
       "         'attitude': 42,\n",
       "         'enthusiasm': 23,\n",
       "         'goaloriented': 1,\n",
       "         'achievement': 25,\n",
       "         'player': 40,\n",
       "         'car': 125,\n",
       "         'owner': 5,\n",
       "         'clean': 22,\n",
       "         'driving': 63,\n",
       "         'license': 12,\n",
       "         'occasional': 5,\n",
       "         'local': 65,\n",
       "         'travel': 99,\n",
       "         'send': 103,\n",
       "         'detailed': 38,\n",
       "         'blocked': 7,\n",
       "         'reference': 42,\n",
       "         'vac': 4,\n",
       "         'title': 42,\n",
       "         'scrub': 6,\n",
       "         'nurse': 188,\n",
       "         'location': 121,\n",
       "         'norwich': 5,\n",
       "         'norfolk': 10,\n",
       "         'annum': 35,\n",
       "         'time': 254,\n",
       "         'largest': 51,\n",
       "         'providers': 29,\n",
       "         'private': 68,\n",
       "         'uk': 496,\n",
       "         'offers': 70,\n",
       "         'suite': 15,\n",
       "         'theatres': 5,\n",
       "         'equipped': 4,\n",
       "         'laminar': 1,\n",
       "         'flow': 16,\n",
       "         'covers': 4,\n",
       "         'wide': 56,\n",
       "         'surgical': 15,\n",
       "         'specialities': 3,\n",
       "         'includes': 38,\n",
       "         'dedicated': 53,\n",
       "         'sterile': 1,\n",
       "         'department': 63,\n",
       "         'undertaking': 11,\n",
       "         'position': 268,\n",
       "         'presents': 1,\n",
       "         'broaden': 2,\n",
       "         'whilst': 72,\n",
       "         'environment': 235,\n",
       "         'enthusiastic': 52,\n",
       "         'theatre': 24,\n",
       "         'essential': 233,\n",
       "         'preferably': 44,\n",
       "         'including': 287,\n",
       "         'major': 52,\n",
       "         'ortho': 1,\n",
       "         'ophthalmic': 1,\n",
       "         'gynae': 1,\n",
       "         'main': 63,\n",
       "         'responsibilities': 143,\n",
       "         'provide': 298,\n",
       "         'exemplary': 1,\n",
       "         'planned': 26,\n",
       "         'patients': 68,\n",
       "         'perioperative': 3,\n",
       "         'area': 185,\n",
       "         'organisation': 171,\n",
       "         'provision': 32,\n",
       "         'operating': 52,\n",
       "         'hpc': 3,\n",
       "         'teams': 89,\n",
       "         'minimum': 95,\n",
       "         'caring': 27,\n",
       "         'desirable': 58,\n",
       "         'applying': 43,\n",
       "         'clinical': 129,\n",
       "         'reasoning': 3,\n",
       "         'complex': 57,\n",
       "         'varied': 25,\n",
       "         'patient': 34,\n",
       "         'case': 23,\n",
       "         'mixes': 1,\n",
       "         'post': 90,\n",
       "         'echadwickeclypserecruitment': 2,\n",
       "         'call': 149,\n",
       "         'recruit': 105,\n",
       "         'clerk': 9,\n",
       "         'covering': 64,\n",
       "         'maternity': 6,\n",
       "         'february': 19,\n",
       "         'mid': 5,\n",
       "         'immediately': 28,\n",
       "         'limited': 54,\n",
       "         'cheques': 6,\n",
       "         'bacs': 6,\n",
       "         'sage': 9,\n",
       "         'accurately': 19,\n",
       "         'reconcile': 2,\n",
       "         'remittances': 1,\n",
       "         'actual': 4,\n",
       "         'receipts': 7,\n",
       "         'prepare': 38,\n",
       "         'banking': 40,\n",
       "         'book': 10,\n",
       "         'timely': 44,\n",
       "         'manner': 68,\n",
       "         'monthly': 54,\n",
       "         'basis': 120,\n",
       "         'managing': 153,\n",
       "         'aged': 9,\n",
       "         'debtors': 2,\n",
       "         'run': 23,\n",
       "         'ensuring': 143,\n",
       "         'invoices': 14,\n",
       "         'processed': 3,\n",
       "         'duplicates': 1,\n",
       "         'log': 3,\n",
       "         'payments': 40,\n",
       "         'chaps': 1,\n",
       "         'deal': 26,\n",
       "         'account': 166,\n",
       "         'payable': 9,\n",
       "         'creditors': 4,\n",
       "         'systems': 267,\n",
       "         'invoicing': 6,\n",
       "         'good': 274,\n",
       "         'currencies': 1,\n",
       "         'computer': 45,\n",
       "         'literate': 21,\n",
       "         'word': 36,\n",
       "         'preferred': 55,\n",
       "         'tight': 21,\n",
       "         'deadlines': 45,\n",
       "         'errors': 3,\n",
       "         'numeracy': 12,\n",
       "         'organised': 24,\n",
       "         'efficient': 39,\n",
       "         'attention': 48,\n",
       "         'detail': 60,\n",
       "         'salespurchaseledgerclerkmaternitycover': 1,\n",
       "         'suffolk': 7,\n",
       "         'north': 59,\n",
       "         'essex': 24,\n",
       "         'cambridgeshire': 18,\n",
       "         'border': 3,\n",
       "         'embarking': 1,\n",
       "         'expansion': 32,\n",
       "         'programme': 84,\n",
       "         'actively': 21,\n",
       "         'tenacious': 9,\n",
       "         'passionate': 26,\n",
       "         'consultant': 87,\n",
       "         'faint': 1,\n",
       "         'hearted': 1,\n",
       "         'drive': 71,\n",
       "         'determination': 13,\n",
       "         'succeed': 31,\n",
       "         'extremely': 28,\n",
       "         'competitive': 120,\n",
       "         'territory': 42,\n",
       "         'span': 2,\n",
       "         'counties': 8,\n",
       "         'focus': 63,\n",
       "         'cambridge': 14,\n",
       "         'newmarket': 3,\n",
       "         'haverhill': 2,\n",
       "         'field': 149,\n",
       "         'involve': 44,\n",
       "         'face': 77,\n",
       "         'targeted': 6,\n",
       "         'making': 35,\n",
       "         'appointments': 29,\n",
       "         'activity': 36,\n",
       "         'recorded': 6,\n",
       "         'track': 93,\n",
       "         'record': 97,\n",
       "         'hunger': 6,\n",
       "         'challenge': 47,\n",
       "         'ahead': 9,\n",
       "         'advantage': 58,\n",
       "         'means': 17,\n",
       "         'transport': 42,\n",
       "         'offer': 155,\n",
       "         'structure': 32,\n",
       "         'career': 235,\n",
       "         'progression': 67,\n",
       "         'possibility': 4,\n",
       "         'interviews': 21,\n",
       "         'place': 50,\n",
       "         'listing': 2,\n",
       "         'process': 191,\n",
       "         'recruitmentsalesexecutive': 1,\n",
       "         'executive': 151,\n",
       "         'dartford': 3,\n",
       "         'kbasic': 2,\n",
       "         'ote': 85,\n",
       "         'bens': 3,\n",
       "         'da': 1,\n",
       "         'se': 3,\n",
       "         'br': 1,\n",
       "         'hungry': 7,\n",
       "         'firmly': 5,\n",
       "         'industry': 214,\n",
       "         'success': 63,\n",
       "         'long': 50,\n",
       "         'term': 56,\n",
       "         'representing': 5,\n",
       "         'premium': 7,\n",
       "         'impressive': 18,\n",
       "         'environmental': 23,\n",
       "         'hygiene': 11,\n",
       "         'generate': 17,\n",
       "         'selling': 98,\n",
       "         'sme': 20,\n",
       "         'contractual': 9,\n",
       "         'sale': 17,\n",
       "         'emphasis': 9,\n",
       "         'solution': 15,\n",
       "         'months': 75,\n",
       "         'polished': 3,\n",
       "         'articulate': 14,\n",
       "         'communicator': 15,\n",
       "         'ideally': 173,\n",
       "         'led': 13,\n",
       "         'advantageous': 39,\n",
       "         'driven': 62,\n",
       "         'planning': 121,\n",
       "         'organizing': 2,\n",
       "         'week': 103,\n",
       "         'customers': 200,\n",
       "         'adapt': 4,\n",
       "         'personalities': 1,\n",
       "         'background': 139,\n",
       "         'industries': 38,\n",
       "         'cleaning': 18,\n",
       "         'logistics': 15,\n",
       "         'round': 4,\n",
       "         'energy': 42,\n",
       "         'key': 244,\n",
       "         'words': 9,\n",
       "         'recycling': 1,\n",
       "         'washroom': 1,\n",
       "         'pest': 1,\n",
       "         'hire': 13,\n",
       "         'businessdevelopmentexecutivefieldsalesdartford': 1,\n",
       "         'eastleigh': 3,\n",
       "         'treasury': 30,\n",
       "         'controller': 17,\n",
       "         'transactional': 5,\n",
       "         'analysis': 100,\n",
       "         'oversight': 3,\n",
       "         'investment': 53,\n",
       "         'compliance': 99,\n",
       "         'sections': 4,\n",
       "         'policies': 57,\n",
       "         'capital': 36,\n",
       "         'liquid': 3,\n",
       "         'resources': 30,\n",
       "         'cashflow': 3,\n",
       "         'managed': 17,\n",
       "         'efficiently': 20,\n",
       "         'deliver': 66,\n",
       "         'consistently': 18,\n",
       "         'kpis': 5,\n",
       "         'kris': 1,\n",
       "         'analysing': 11,\n",
       "         'shortfalls': 1,\n",
       "         'putting': 6,\n",
       "         'action': 23,\n",
       "         'plans': 102,\n",
       "         'remediate': 1,\n",
       "         'outsourced': 6,\n",
       "         'managers': 99,\n",
       "         'custodians': 1,\n",
       "         'mutual': 2,\n",
       "         'operations': 89,\n",
       "         'developments': 17,\n",
       "         'transacted': 1,\n",
       "         'effectively': 64,\n",
       "         'endtoend': 4,\n",
       "         'processes': 93,\n",
       "         'risks': 31,\n",
       "         'controls': 71,\n",
       "         'documented': 5,\n",
       "         'effective': 82,\n",
       "         'regularly': 34,\n",
       "         'test': 107,\n",
       "         'accordance': 41,\n",
       "         'risk': 135,\n",
       "         'framework': 18,\n",
       "         'stakeholders': 31,\n",
       "         'levels': 106,\n",
       "         'assumptions': 4,\n",
       "         'positively': 5,\n",
       "         'bring': 20,\n",
       "         'journey': 5,\n",
       "         'written': 63,\n",
       "         'fluent': 12,\n",
       "         'confident': 41,\n",
       "         'spoken': 8,\n",
       "         'principles': 16,\n",
       "         'significant': 39,\n",
       "         'practical': 29,\n",
       "         'coupled': 9,\n",
       "         'analytical': 39,\n",
       "         'organisational': 29,\n",
       "         'proactive': 36,\n",
       "         'highly': 149,\n",
       "         'motivated': 71,\n",
       "         'change': 51,\n",
       "         'orientated': 11,\n",
       "         'identify': 50,\n",
       "         'obstacles': 2,\n",
       "         'clear': 35,\n",
       "         'data': 89,\n",
       "         'warehouse': 4,\n",
       "         'architectures': 7,\n",
       "         'desktop': 3,\n",
       "         'microsoft': 46,\n",
       "         'powerpoint': 7,\n",
       "         'understand': 40,\n",
       "         'evaluate': 14,\n",
       "         'interpret': 11,\n",
       "         'diverse': 25,\n",
       "         'aca': 33,\n",
       "         'acca': 30,\n",
       "         'cima': 19,\n",
       "         'equivalent': 74,\n",
       "         'august': 1,\n",
       "         'clarke': 1,\n",
       "         'acting': 70,\n",
       "         'discriminate': 9,\n",
       "         'grounds': 8,\n",
       "         'age': 26,\n",
       "         'race': 16,\n",
       "         'gender': 16,\n",
       "         'disability': 30,\n",
       "         'creed': 2,\n",
       "         'sexual': 14,\n",
       "         'orientation': 15,\n",
       "         'comply': 17,\n",
       "         'legislation': 27,\n",
       "         'hear': 30,\n",
       "         'back': 32,\n",
       "         'investmentstreasurycontroller': 1,\n",
       "         'hemel': 4,\n",
       "         'hempstead': 4,\n",
       "         'payroll': 38,\n",
       "         'european': 30,\n",
       "         'employees': 32,\n",
       "         'previously': 14,\n",
       "         'worked': 27,\n",
       "         'happy': 15,\n",
       "         'monday': 39,\n",
       "         'friday': 46,\n",
       "         'pm': 69,\n",
       "         'engineering': 336,\n",
       "         'assessor': 5,\n",
       "         'instructor': 3,\n",
       "         'yorkshire': 26,\n",
       "         'depending': 39,\n",
       "         'holiday': 78,\n",
       "         'bank': 73,\n",
       "         'holidays': 31,\n",
       "         'pension': 134,\n",
       "         'life': 79,\n",
       "         'assurance': 55,\n",
       "         'arena': 8,\n",
       "         'continue': 24,\n",
       "         'trend': 2,\n",
       "         'return': 59,\n",
       "         'expect': 32,\n",
       "         'packages': 27,\n",
       "         'receive': 110,\n",
       "         'delivering': 53,\n",
       "         'apprenticeship': 11,\n",
       "         'operation': 16,\n",
       "         'workshops': 6,\n",
       "         'assessment': 42,\n",
       "         'workshop': 12,\n",
       "         'qualification': 95,\n",
       "         'assessors': 2,\n",
       "         'award': 36,\n",
       "         'suitable': 53,\n",
       "         'live': 83,\n",
       "         'areas': 135,\n",
       "         'barnsley': 2,\n",
       "         'batley': 1,\n",
       "         'castleford': 1,\n",
       "         'chesterfield': 2,\n",
       "         'dewsbury': 2,\n",
       "         'doncaster': 13,\n",
       "         'huddersfield': 3,\n",
       "         'leeds': 16,\n",
       "         'morley': 1,\n",
       "         'pontefract': 1,\n",
       "         'rotherham': 3,\n",
       "         'sheffield': 9,\n",
       "         'wakefield': 3,\n",
       "         'additional': 57,\n",
       "         'defined': 39,\n",
       "         'conduct': 31,\n",
       "         'agencies': 31,\n",
       "         'businesses': 37,\n",
       "         'regulations': 35,\n",
       "         'outskirts': 5,\n",
       "         'poole': 8,\n",
       "         'dorset': 13,\n",
       "         'interface': 13,\n",
       "         'companies': 91,\n",
       "         'entire': 8,\n",
       "         'challenging': 39,\n",
       "         'identifying': 29,\n",
       "         'creating': 15,\n",
       "         'promoting': 32,\n",
       "         'base': 73,\n",
       "         'operational': 50,\n",
       "         'supporting': 66,\n",
       "         'closely': 45,\n",
       "         'director': 92,\n",
       "         'pivotal': 5,\n",
       "         'link': 11,\n",
       "         'objectives': 57,\n",
       "         'initiative': 35,\n",
       "         'enabling': 15,\n",
       "         'reached': 2,\n",
       "         'achieved': 27,\n",
       "         'electronics': 58,\n",
       "         'blue': 15,\n",
       "         'chip': 11,\n",
       "         'large': 82,\n",
       "         'corporate': 77,\n",
       "         'fantastic': 94,\n",
       "         'reputable': 13,\n",
       "         'allowance': 42,\n",
       "         'parking': 18,\n",
       "         'make': 77,\n",
       "         'newly': 15,\n",
       "         'created': 12,\n",
       "         'oil': 32,\n",
       "         'operator': 13,\n",
       "         'malaysia': 2,\n",
       "         'porduction': 1,\n",
       "         'technologist': 2,\n",
       "         'technology': 82,\n",
       "         'expertise': 34,\n",
       "         'satellites': 2,\n",
       "         'susurface': 1,\n",
       "         'promary': 1,\n",
       "         'satellite': 4,\n",
       "         'project': 236,\n",
       "         'maturation': 1,\n",
       "         'bachelor': 2,\n",
       "         'degree': 99,\n",
       "         'petroleum': 3,\n",
       "         'yrs': 2,\n",
       "         'gas': 51,\n",
       "         'reservior': 1,\n",
       "         'conceptual': 2,\n",
       "         'design': 337,\n",
       "         'subsea': 3,\n",
       "         'reservoir': 9,\n",
       "         'uncertainties': 1,\n",
       "         'deepwater': 1,\n",
       "         'insurance': 95,\n",
       "         'horsham': 5,\n",
       "         'dep': 1,\n",
       "         'talented': 26,\n",
       "         'opening': 15,\n",
       "         'immaculate': 1,\n",
       "         'presentation': 26,\n",
       "         'top': 57,\n",
       "         'moved': 1,\n",
       "         'stepping': 1,\n",
       "         'stone': 1,\n",
       "         'focused': 47,\n",
       "         'sell': 35,\n",
       "         'initially': 15,\n",
       "         'entail': 4,\n",
       "         'inception': 9,\n",
       "         'midterm': 2,\n",
       "         'renewals': 8,\n",
       "         'claims': 26,\n",
       "         'motor': 32,\n",
       "         'breakdown': 8,\n",
       "         'insurances': 3,\n",
       "         'communicate': 47,\n",
       "         'types': 10,\n",
       "         'house': 21,\n",
       "         'hands': 17,\n",
       "         'expected': 65,\n",
       "         'certificate': 20,\n",
       "         'consists': 6,\n",
       "         'exams': 3,\n",
       "         'pass': 8,\n",
       "         'promotes': 8,\n",
       "         'real': 28,\n",
       "         'path': 14,\n",
       "         'vehicle': 50,\n",
       "         'purchaser': 3,\n",
       "         'birkenhead': 1,\n",
       "         'southport': 5,\n",
       "         'summary': 13,\n",
       "         'rewarding': 25,\n",
       "         'buying': 7,\n",
       "         'branch': 46,\n",
       "         'ended': 1,\n",
       "         'perfect': 15,\n",
       "         'outgoing': 7,\n",
       "         'minded': 9,\n",
       "         'rapport': 8,\n",
       "         'discipline': 36,\n",
       "         'note': 52,\n",
       "         'automotive': 41,\n",
       "         'provided': 65,\n",
       "         'remarketing': 1,\n",
       "         'recognisable': 4,\n",
       "         'distinctive': 1,\n",
       "         'powerful': 2,\n",
       "         'branding': 1,\n",
       "         'ago': 10,\n",
       "         'objective': 2,\n",
       "         'quickly': 18,\n",
       "         'safety': 110,\n",
       "         'easily': 7,\n",
       "         'growing': 87,\n",
       "         'presence': 7,\n",
       "         'remits': 1,\n",
       "         'firstly': 1,\n",
       "         'suggests': 1,\n",
       "         'purchasing': 18,\n",
       "         'vehicles': 10,\n",
       "         'directly': 40,\n",
       "         'enquiry': 1,\n",
       "         'online': 110,\n",
       "         'introductory': 2,\n",
       "         'initial': 25,\n",
       "         'inspect': 3,\n",
       "         'buy': 8,\n",
       "         'workload': 19,\n",
       "         'diary': 8,\n",
       "         'class': 25,\n",
       "         'proactively': 21,\n",
       "         'seeking': 84,\n",
       "         'generating': 18,\n",
       "         'feel': 29,\n",
       "         'foremost': 2,\n",
       "         'confidence': 30,\n",
       "         'selfmotivation': 4,\n",
       "         'achieve': 75,\n",
       "         'great': 106,\n",
       "         'building': 83,\n",
       "         'engage': 9,\n",
       "         'important': 47,\n",
       "         'numbers': 7,\n",
       "         'mental': 51,\n",
       "         'agility': 1,\n",
       "         'lots': 5,\n",
       "         'feet': 5,\n",
       "         'supported': 23,\n",
       "         'comfortable': 18,\n",
       "         'performers': 6,\n",
       "         'earning': 10,\n",
       "         'saturday': 15,\n",
       "         'sunday': 12,\n",
       "         'weekdays': 2,\n",
       "         'vehiclepurchasercarsales': 1,\n",
       "         'marine': 24,\n",
       "         'engines': 10,\n",
       "         'specialist': 148,\n",
       "         'product': 191,\n",
       "         'supportslough': 1,\n",
       "         'berkshirec': 1,\n",
       "         'annual': 64,\n",
       "         'contributory': 14,\n",
       "         'health': 187,\n",
       "         'scheme': 113,\n",
       "         'death': 2,\n",
       "         'caterpillar': 6,\n",
       "         'dealers': 11,\n",
       "         'world': 74,\n",
       "         'official': 2,\n",
       "         'dealer': 6,\n",
       "         'africa': 5,\n",
       "         'middle': 12,\n",
       "         'western': 4,\n",
       "         'siberia': 2,\n",
       "         'complete': 60,\n",
       "         'power': 49,\n",
       "         'generation': 36,\n",
       "         'construction': 55,\n",
       "         'mining': 3,\n",
       "         'materials': 30,\n",
       "         'equipment': 172,\n",
       "         'aftersales': 1,\n",
       "         'secondtonone': 1,\n",
       "         'agreements': 9,\n",
       "         'parts': 21,\n",
       "         'availability': 17,\n",
       "         'cat': 1,\n",
       "         'certified': 4,\n",
       "         'engineers': 118,\n",
       "         'engineer': 285,\n",
       "         'diesel': 9,\n",
       "         'engine': 4,\n",
       "         'superb': 17,\n",
       "         'global': 114,\n",
       "         'offering': 66,\n",
       "         'prospects': 33,\n",
       "         'chance': 37,\n",
       "         'internationally': 12,\n",
       "         'pioneer': 3,\n",
       "         'practices': 37,\n",
       "         'rapidly': 23,\n",
       "         'developing': 93,\n",
       "         'market': 219,\n",
       "         'units': 17,\n",
       "         ...})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check counts for each remaining words\n",
    "\n",
    "word_counts = Counter(w for words in data_tk for w in words)\n",
    "word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized Data with more than one occurance:\n",
      " ['accountant', 'partqualified', 'south', 'east', 'london', 'client', 'successful', 'manufacturing', 'company', 'requirement', 'accountant', 'permanent', 'role', 'modern', 'offices', 'south', 'east', 'london', 'role', 'credit', 'control', 'purchase', 'sales', 'ledger', 'daily', 'collection', 'debts', 'phone', 'letter', 'email', 'handling', 'ledger', 'accounts', 'handling', 'accounts', 'negotiating', 'payment', 'terms', 'cash', 'reconciliation', 'accounts', 'adhoc', 'administration', 'duties', 'business', 'person', 'ideal', 'candidate', 'previous', 'experience', 'credit', 'control', 'capacity', 'possess', 'exceptional', 'customer', 'service', 'communication', 'skills', 'part', 'fully', 'qualified', 'accountant', 'considered', 'role']\n"
     ]
    }
   ],
   "source": [
    "# Filter out words that appear only once\n",
    "\n",
    "data_tk = [[w for w in words if word_counts[w] > 1] for words in data_tk]\n",
    "\n",
    "print(\"Tokenized Data with more than one occurance:\\n\", data_tk[emp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size:  5218\n",
      "Total number of tokens:  102975\n",
      "Lexical diversity:  0.05067249332362224\n",
      "Total number of reviews: 776\n",
      "Average review length: 132.69974226804123\n",
      "Maximun review length: 471\n",
      "Minimun review length: 12\n",
      "Standard deviation of review length: 70.3782402519735\n"
     ]
    }
   ],
   "source": [
    "# Check stats after eliminating words that appear only once\n",
    "\n",
    "stats_print(data_tk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('experience', 1276),\n",
       " ('sales', 1030),\n",
       " ('role', 946),\n",
       " ('work', 861),\n",
       " ('business', 832),\n",
       " ('team', 789),\n",
       " ('working', 719),\n",
       " ('job', 688),\n",
       " ('care', 675),\n",
       " ('skills', 669),\n",
       " ('company', 614),\n",
       " ('client', 594),\n",
       " ('management', 572),\n",
       " ('manager', 519),\n",
       " ('support', 501),\n",
       " ('uk', 496),\n",
       " ('service', 481),\n",
       " ('excellent', 455),\n",
       " ('development', 431),\n",
       " ('required', 399),\n",
       " ('based', 376),\n",
       " ('opportunity', 372),\n",
       " ('services', 369),\n",
       " ('knowledge', 349),\n",
       " ('apply', 349),\n",
       " ('successful', 340),\n",
       " ('training', 338),\n",
       " ('design', 337),\n",
       " ('engineering', 336),\n",
       " ('customer', 335),\n",
       " ('recruitment', 335),\n",
       " ('salary', 322),\n",
       " ('candidate', 319),\n",
       " ('clients', 310),\n",
       " ('high', 309),\n",
       " ('join', 302),\n",
       " ('ability', 301),\n",
       " ('strong', 299),\n",
       " ('provide', 298),\n",
       " ('home', 291),\n",
       " ('ensure', 290),\n",
       " ('leading', 289),\n",
       " ('including', 287),\n",
       " ('engineer', 285),\n",
       " ('financial', 279),\n",
       " ('good', 274),\n",
       " ('staff', 271),\n",
       " ('position', 268),\n",
       " ('systems', 267),\n",
       " ('full', 263)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check 50 most common words\n",
    "\n",
    "# Indicate _ to only include words in the list\n",
    "most_common_words = [w for w, _ in word_counts.most_common(50)]\n",
    "\n",
    "# Check with the numbers\n",
    "most_common_words_count = [w for w in word_counts.most_common(50)]\n",
    "most_common_words_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized Data without 50 most frequent words:\n",
      " ['accountant', 'partqualified', 'south', 'east', 'london', 'manufacturing', 'requirement', 'accountant', 'permanent', 'modern', 'offices', 'south', 'east', 'london', 'credit', 'control', 'purchase', 'ledger', 'daily', 'collection', 'debts', 'phone', 'letter', 'email', 'handling', 'ledger', 'accounts', 'handling', 'accounts', 'negotiating', 'payment', 'terms', 'cash', 'reconciliation', 'accounts', 'adhoc', 'administration', 'duties', 'person', 'ideal', 'previous', 'credit', 'control', 'capacity', 'possess', 'exceptional', 'communication', 'part', 'fully', 'qualified', 'accountant', 'considered']\n"
     ]
    }
   ],
   "source": [
    "# Filter out top 50 most common words based on document frequency\n",
    "\n",
    "data_tk = [[w for w in words if w not in most_common_words] for words in data_tk]\n",
    "\n",
    "print(\"Tokenized Data without 50 most frequent words:\\n\", data_tk[emp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size:  5168\n",
      "Total number of tokens:  80068\n",
      "Lexical diversity:  0.06454513663386122\n",
      "Total number of reviews: 776\n",
      "Average review length: 103.18041237113403\n",
      "Maximun review length: 390\n",
      "Minimun review length: 7\n",
      "Standard deviation of review length: 56.69634188671351\n"
     ]
    }
   ],
   "source": [
    "# Check stats after eliminating 50 most common words \n",
    "\n",
    "stats_print(data_tk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving required outputs\n",
    "Save the vocabulary, bigrams and job advertisment txt as per spectification.\n",
    "- vocab.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine tokens and save output as a text file\n",
    "\n",
    "combined_data = [\" \".join(tokens) for tokens in data_tk]\n",
    "output_file = \"cleaned_descriptions.txt\"\n",
    "\n",
    "with open(output_file, 'w', encoding='utf-8') as f:\n",
    "    for description in combined_data:\n",
    "        f.write(description + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a list of sorted vocabs as a text file\n",
    "\n",
    "unique_words = set(w for words in data_tk for w in words)\n",
    "sorted_unique_words = sorted(unique_words)\n",
    "\n",
    "vocab_file = \"vocab.txt\"\n",
    "\n",
    "with open(vocab_file, 'w') as f:\n",
    "    for index, word in enumerate(sorted_unique_words):\n",
    "        f.write(f\"{word}:{index}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "By completing this task, we have set the stage for more advanced analyses and modeling in subsequent tasks. Our clean and well-structured dataset, along with the insights gained through exploratory data analysis, will enable us to build robust machine learning models and extract meaningful information from the data. The outputs from this task will be used further in the following tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Couple of notes for all code blocks in this notebook\n",
    "- please provide proper comment on your code\n",
    "- Please re-start and run all cells to make sure codes are runable and include your output in the submission.   \n",
    "<span style=\"color: red\"> This markdown block can be removed once the task is completed. </span>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
